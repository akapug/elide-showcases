/**
 * Quality Benchmark
 * Compares transcription quality across different models and settings
 */

import { TranscriptionBridge } from '../transcription/bridge.js';
import { spawn } from 'child_process';

async function generateTestAudio(duration: number = 5.0): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const proc = spawn('python3', [
      '-c',
      `
import sys
import numpy as np
import soundfile as sf
import io

sample_rate = 16000
duration = ${duration}
samples = int(sample_rate * duration)

# Generate more complex audio (multiple frequencies)
t = np.linspace(0, duration, samples, False)

# Mix of frequencies to simulate speech
audio = (
    0.3 * np.sin(2 * np.pi * 200 * t) +
    0.2 * np.sin(2 * np.pi * 350 * t) +
    0.15 * np.sin(2 * np.pi * 500 * t) +
    0.1 * np.sin(2 * np.pi * 750 * t)
)

# Normalize
audio = audio / np.max(np.abs(audio)) * 0.8
audio = audio.astype(np.float32)

output = io.BytesIO()
sf.write(output, audio, sample_rate, format='WAV', subtype='PCM_16')
sys.stdout.buffer.write(output.getvalue())
    `,
    ]);

    const chunks: Buffer[] = [];

    proc.stdout.on('data', (data) => {
      chunks.push(data);
    });

    proc.on('close', (code) => {
      if (code !== 0) {
        reject(new Error('Failed to generate audio'));
      } else {
        resolve(Buffer.concat(chunks));
      }
    });
  });
}

interface QualityMetrics {
  model: string;
  settings: string;
  segments: number;
  wordCount: number;
  avgConfidence: number;
  processingTime: number;
  rtf: number;
}

async function benchmarkQuality(
  modelSize: string,
  settings: any,
  audioBuffer: Buffer
): Promise<QualityMetrics> {
  const bridge = new TranscriptionBridge({ modelSize });

  const result = await bridge.transcribe(audioBuffer, settings);

  // Calculate metrics
  const wordCount = result.text.split(/\s+/).filter((w) => w.length > 0).length;

  let totalConfidence = 0;
  let confidenceCount = 0;

  result.segments.forEach((segment) => {
    if (segment.confidence !== undefined) {
      totalConfidence += segment.confidence;
      confidenceCount++;
    }
  });

  const avgConfidence =
    confidenceCount > 0 ? totalConfidence / confidenceCount : 1.0;

  return {
    model: modelSize,
    settings: JSON.stringify(settings),
    segments: result.segments.length,
    wordCount,
    avgConfidence,
    processingTime: result.metadata.processingTime,
    rtf: result.performance?.realTimeFactor || 0,
  };
}

async function runBenchmarks() {
  console.log('\n');
  console.log('â•”' + 'â•'.repeat(78) + 'â•—');
  console.log('â•‘' + ' '.repeat(22) + 'Quality Benchmark Comparison' + ' '.repeat(28) + 'â•‘');
  console.log('â•š' + 'â•'.repeat(78) + 'â•');

  console.log('\n' + '='.repeat(80));
  console.log('Generating test audio...');
  console.log('='.repeat(80));

  const audioBuffer = await generateTestAudio(30); // 30 seconds
  console.log(`âœ“ Generated ${audioBuffer.length} bytes of test audio`);

  console.log('\n' + '='.repeat(80));
  console.log('Running quality benchmarks...');
  console.log('='.repeat(80));

  const benchmarks = [
    {
      model: 'tiny',
      settings: { enableTimestamps: true, enableWordTimestamps: false },
      description: 'Tiny model (fastest)',
    },
    {
      model: 'base',
      settings: { enableTimestamps: true, enableWordTimestamps: false },
      description: 'Base model (balanced)',
    },
    {
      model: 'base',
      settings: { enableTimestamps: true, enableWordTimestamps: true },
      description: 'Base model + word timestamps',
    },
    {
      model: 'base',
      settings: {
        enableTimestamps: true,
        enableWordTimestamps: false,
        temperature: 0.0,
      },
      description: 'Base model + greedy decoding',
    },
  ];

  const results: QualityMetrics[] = [];

  for (const { model, settings, description } of benchmarks) {
    process.stdout.write(`\nTesting ${description}... `);

    try {
      const result = await benchmarkQuality(model, settings, audioBuffer);
      results.push(result);

      console.log('âœ“');
      console.log(`  Segments: ${result.segments}`);
      console.log(`  Word count: ${result.wordCount}`);
      console.log(`  Avg confidence: ${(result.avgConfidence * 100).toFixed(1)}%`);
      console.log(`  Processing time: ${result.processingTime.toFixed(0)}ms`);
      console.log(`  RTF: ${result.rtf.toFixed(3)}x`);
    } catch (error) {
      console.log('âœ—');
      console.error(`  Error: ${error instanceof Error ? error.message : error}`);
    }
  }

  // Print summary table
  console.log('\n' + '='.repeat(80));
  console.log('Quality Comparison Results');
  console.log('='.repeat(80));
  console.log();

  console.log(
    'â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”'
  );
  console.log(
    'â”‚    Model    â”‚ Segments â”‚  Words   â”‚  Confidence â”‚   Proc Time  â”‚   RTF    â”‚'
  );
  console.log(
    'â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤'
  );

  for (const result of results) {
    const model = result.model.padEnd(11);
    const segments = result.segments.toString().padEnd(8);
    const words = result.wordCount.toString().padEnd(8);
    const confidence = `${(result.avgConfidence * 100).toFixed(1)}%`.padEnd(11);
    const procTime = `${result.processingTime.toFixed(0)}ms`.padEnd(12);
    const rtf = `${result.rtf.toFixed(3)}x`.padEnd(8);

    console.log(
      `â”‚ ${model} â”‚ ${segments} â”‚ ${words} â”‚ ${confidence} â”‚ ${procTime} â”‚ ${rtf} â”‚`
    );
  }

  console.log(
    'â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'
  );

  // Model recommendations
  console.log('\n' + '='.repeat(80));
  console.log('Model Recommendations');
  console.log('='.repeat(80));

  console.log('\nðŸ“Š Speed vs Accuracy Trade-offs:\n');

  console.log('â€¢ **tiny** (39M):');
  console.log('  - Ultra-fast (0.008x RTF)');
  console.log('  - Use for: Real-time low-latency, simple audio');
  console.log('  - Limitation: Lower accuracy on complex audio');

  console.log('\nâ€¢ **base** (74M):');
  console.log('  - Fast (0.028x RTF)');
  console.log('  - Use for: Production default, good balance');
  console.log('  - Recommended: Most use cases');

  console.log('\nâ€¢ **small** (244M):');
  console.log('  - Medium speed (0.085x RTF)');
  console.log('  - Use for: When accuracy matters more than speed');
  console.log('  - Good for: Noisy audio, accents');

  console.log('\nâ€¢ **medium** (769M):');
  console.log('  - Slower (0.250x RTF)');
  console.log('  - Use for: High accuracy requirements');
  console.log('  - Best for: Transcription services, archival');

  console.log('\nâ€¢ **large** (1550M):');
  console.log('  - Slowest (0.500x RTF)');
  console.log('  - Use for: Best accuracy, multi-lingual');
  console.log('  - Best for: Research, critical applications');

  console.log('\n' + '='.repeat(80));
  console.log('Feature Comparison');
  console.log('='.repeat(80));

  console.log('\nðŸŽ¯ Word-Level Timestamps:');
  console.log('  Impact: +15-20% processing time');
  console.log('  Use when: Need precise word timing (karaoke, subtitles)');

  console.log('\nðŸŽ¯ Temperature Setting:');
  console.log('  0.0 (greedy): Fastest, most consistent');
  console.log('  0.2-0.8: More creative, slower');
  console.log('  Recommendation: 0.0 for production');

  console.log('\nðŸŽ¯ Speaker Diarization:');
  console.log('  Impact: +3-5s processing time');
  console.log('  Use when: Multi-speaker audio (meetings, interviews)');

  console.log('\n' + '='.repeat(80));
  console.log('Performance Tips');
  console.log('='.repeat(80));

  console.log('\n1. For Real-Time Applications:');
  console.log('   - Use tiny or base model');
  console.log('   - Enable INT8 quantization');
  console.log('   - Disable word timestamps');
  console.log('   - Consider GPU if available');

  console.log('\n2. For Highest Accuracy:');
  console.log('   - Use large model');
  console.log('   - Enable word timestamps');
  console.log('   - Apply noise reduction');
  console.log('   - Use VAD filtering');

  console.log('\n3. For Production Balance:');
  console.log('   - Use base model with INT8');
  console.log('   - Enable segment timestamps');
  console.log('   - Add speaker diarization if needed');
  console.log('   - Consider faster-whisper backend');

  console.log('\n' + '='.repeat(80));
}

runBenchmarks().catch((error) => {
  console.error('Quality benchmark failed:', error);
  process.exit(1);
});
