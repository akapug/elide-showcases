PORT=3000
NODE_ENV=development

# Embedding models
TEXT_MODEL=sentence-transformers/all-MiniLM-L6-v2
IMAGE_MODEL=openai/clip-vit-base-patch32

# Cache settings
CACHE_MAX_SIZE=10000
CACHE_TTL=3600000

# Performance settings
BATCH_SIZE=100
MAX_WORKERS=4
SHARED_MEMORY_SIZE=1073741824
